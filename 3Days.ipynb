{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a2d1f2",
   "metadata": {},
   "source": [
    "AIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85d05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tankers in data.csv: 463\n",
      "Unique tankers in data2.csv: 446\n",
      "Unique tankers in data3.csv: 441\n",
      "Common between data1 and data2: 397\n",
      "Common between data1 and data3: 378\n",
      "Common between data2 and data3: 398\n",
      "Present in all three: 361\n"
     ]
    }
   ],
   "source": [
    "# Read data1, data2 and data3, extract tankers (VesselType==80), compute overlaps and produce a map\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import IFrame, DivIcon, PolyLine\n",
    "from folium.plugins import Fullscreen\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize, rgb2hex\n",
    "# Helper: find a timestamp column in a dataframe\n",
    "def find_timestamp_col(df):\n",
    "    candidates = ['BaseDateTime','Timestamp','Date','Datetime','date','time','BaseDateTimeUTC','DateTimeUTC','received_at','timestamp']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "# Load CSVs (adjust paths if needed)\n",
    "df1 = pd.read_csv('data.csv', low_memory=False)\n",
    "df2 = pd.read_csv('data2.csv', low_memory=False)\n",
    "df3 = pd.read_csv('data3.csv', low_memory=False)\n",
    "# Filter tankers\n",
    "t1 = df1[df1.get('VesselType') == 80].copy()\n",
    "t2 = df2[df2.get('VesselType') == 80].copy()\n",
    "t3 = df3[df3.get('VesselType') == 80].copy()\n",
    "# Unique counts\n",
    "u1 = set(t1['MMSI'].dropna().unique())\n",
    "u2 = set(t2['MMSI'].dropna().unique())\n",
    "u3 = set(t3['MMSI'].dropna().unique())\n",
    "print(f'Unique tankers in data.csv: {len(u1)}')\n",
    "print(f'Unique tankers in data2.csv: {len(u2)}')\n",
    "print(f'Unique tankers in data3.csv: {len(u3)}')\n",
    "# Intersections\n",
    "print(f'Common between data1 and data2: {len(u1 & u2)}')\n",
    "print(f'Common between data1 and data3: {len(u1 & u3)}')\n",
    "print(f'Common between data2 and data3: {len(u2 & u3)}')\n",
    "print(f'Present in all three: {len(u1 & u2 & u3)}')\n",
    "# Detect timestamp columns\n",
    "ts1 = find_timestamp_col(t1)\n",
    "ts2 = find_timestamp_col(t2)\n",
    "ts3 = find_timestamp_col(t3)\n",
    "if ts1 is not None:\n",
    "    t1[ts1] = pd.to_datetime(t1[ts1], errors='coerce')\n",
    "if ts2 is not None:\n",
    "    t2[ts2] = pd.to_datetime(t2[ts2], errors='coerce')\n",
    "if ts3 is not None:\n",
    "    t3[ts3] = pd.to_datetime(t3[ts3], errors='coerce')\n",
    "# Tag source\n",
    "t1['__source'] = 'data1'\n",
    "t2['__source'] = 'data2'\n",
    "t3['__source'] = 'data3'\n",
    "# Unified timestamp column for ordering across files\n",
    "t1['_ts'] = t1[ts1] if ts1 is not None else pd.NaT\n",
    "t2['_ts'] = t2[ts2] if ts2 is not None else pd.NaT\n",
    "t3['_ts'] = t3[ts3] if ts3 is not None else pd.NaT\n",
    "# Combine datasets preserving chronological info when available\n",
    "t_all = pd.concat([t1, t2, t3], ignore_index=True, sort=False)\n",
    "# Determine last position per MMSI: prefer data3 > data2 > data1\n",
    "last_positions = []\n",
    "all_mmsis = sorted(set(t_all['MMSI'].dropna().unique()))\n",
    "for mmsi in all_mmsis:\n",
    "    if mmsi in u3:\n",
    "        group = t3[t3['MMSI'] == mmsi]\n",
    "        if ts3 is not None:\n",
    "            group = group.sort_values(ts3)\n",
    "        row = group.iloc[-1] if len(group) else None\n",
    "    elif mmsi in u2:\n",
    "        group = t2[t2['MMSI'] == mmsi]\n",
    "        if ts2 is not None:\n",
    "            group = group.sort_values(ts2)\n",
    "        row = group.iloc[-1] if len(group) else None\n",
    "    else:\n",
    "        group = t1[t1['MMSI'] == mmsi]\n",
    "        if ts1 is not None:\n",
    "            group = group.sort_values(ts1)\n",
    "        row = group.iloc[-1] if len(group) else None\n",
    "    if row is not None:\n",
    "        last_positions.append(row)\n",
    "# Convert to DataFrame\n",
    "if last_positions:\n",
    "    last_df = pd.DataFrame(last_positions)\n",
    "else:\n",
    "    last_df = pd.DataFrame(columns=t_all.columns)\n",
    "# Compute overall latest timestamp across all data (for disappearance detection)\n",
    "overall_latest = t_all['_ts'].max() if '_ts' in t_all.columns and t_all['_ts'].notna().any() else None\n",
    "# Build a color map across all MMSIs\n",
    "unique_vessels = list(all_mmsis)\n",
    "colors = cm.viridis(Normalize()(np.arange(len(unique_vessels))))\n",
    "color_map = {v: rgb2hex(c) for v, c in zip(unique_vessels, colors)}\n",
    "# Create the map centered on average last positions (fallback)\n",
    "if len(last_df):\n",
    "    center = [last_df['LAT'].astype(float).mean(), last_df['LON'].astype(float).mean()]\n",
    "else:\n",
    "    center = [0, 0]\n",
    "m = folium.Map(location=center, zoom_start=5, tiles='CartoDB dark_matter')\n",
    "folium.TileLayer('https://tiles.openseamap.org/seamark/{z}/{x}/{y}.png', name='SeaMarks', attr='OpenSeaMap - seamark').add_to(m)\n",
    "Fullscreen().add_to(m)\n",
    "# Plot trails for each MMSI using points from all files ordered by unified timestamp when available\n",
    "for mmsi in all_mmsis:\n",
    "    group = t_all[t_all['MMSI'] == mmsi].copy()\n",
    "    # prefer _ts if available, otherwise try specific columns\n",
    "    if group['_ts'].notna().any():\n",
    "        group = group.sort_values('_ts')\n",
    "    else:\n",
    "        if ts1 in group.columns and group[ts1].notna().any():\n",
    "            group = group.sort_values(ts1)\n",
    "        elif ts2 in group.columns and group[ts2].notna().any():\n",
    "            group = group.sort_values(ts2)\n",
    "        elif ts3 in group.columns and group[ts3].notna().any():\n",
    "            group = group.sort_values(ts3)\n",
    "    coords = [(float(r['LAT']), float(r['LON'])) for _, r in group.iterrows() if pd.notna(r.get('LAT')) and pd.notna(r.get('LON'))]\n",
    "    if len(coords) >= 2:\n",
    "        trail_color = color_map.get(mmsi, '#00ffff')\n",
    "        PolyLine(locations=coords, color=trail_color, weight=2, opacity=0.9, dash_array='6,6').add_to(m)\n",
    "# Add last-position markers (SVG arrows) â€” data3 wins if present\n",
    "for _, row in last_df.iterrows():\n",
    "    lat = row.get('LAT')\n",
    "    lon = row.get('LON')\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "    mmsi = row.get('MMSI')\n",
    "    color = color_map.get(mmsi, '#00ffff')\n",
    "    heading = row.get('Heading')\n",
    "    try:\n",
    "        heading = float(heading)\n",
    "    except Exception:\n",
    "        heading = 0.0\n",
    "    # determine last timestamp for this ship\n",
    "    last_ts = row.get('_ts') if pd.notna(row.get('_ts')) else (row.get(ts3) if ts3 in row and pd.notna(row.get(ts3)) else (row.get(ts2) if ts2 in row and pd.notna(row.get(ts2)) else (row.get(ts1) if ts1 in row and pd.notna(row.get(ts1)) else None)))\n",
    "    disappeared = False\n",
    "    if overall_latest is not None and last_ts is not None and pd.notna(last_ts):\n",
    "        try:\n",
    "            disappeared = (overall_latest - pd.to_datetime(last_ts)) > pd.Timedelta(days=1)\n",
    "        except Exception:\n",
    "            disappeared = False\n",
    "    svg_size = 44\n",
    "    # if disappeared, add a small red exclamation overlay in top-right\n",
    "    ex_html = '<span style=\"position:absolute;top:0;right:0;color:#ff3333;font-weight:bold;font-size:18px;\">&#x2757;</span>' if disappeared else ''\n",
    "    svg = f'''<div style=\"position:relative;width:{svg_size}px;height:{svg_size}px;display:flex;align-items:center;justify-content:center;\">{ex_html}\n",
    "    <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{svg_size}\" height=\"{svg_size}\" viewBox=\"0 0 24 24\" style=\"transform: rotate({heading}deg); transform-origin: 12px 12px;\">\n",
    "      <path d=\"M12 2 L19 21 L12 17 L5 21 Z\" fill=\"{color}\" stroke=\"#ffffff\" stroke-width=\"1\" />\n",
    "    </svg>\n",
    "    </div>'''\n",
    "    icon = DivIcon(html=svg)\n",
    "    source = row.get('__source', '')\n",
    "    ts_val = row.get(ts3) if (ts3 in row and pd.notna(row.get(ts3)) and source == 'data3') else (row.get(ts2) if (ts2 in row and pd.notna(row.get(ts2)) and source == 'data2') else (row.get(ts1) if (ts1 in row and pd.notna(row.get(ts1)) and source == 'data1') else row.get('_ts')))\n",
    "    popup_html = f\"MMSI: {mmsi}<br>Vessel: {row.get('VesselName','')}<br>Speed (SOG): {row.get('SOG','')}<br>Heading: {heading}<br>Source: {source}<br>Time: {ts_val}\"\n",
    "    iframe = IFrame(popup_html, width=320, height=150)\n",
    "    popup = folium.Popup(iframe, max_width=360)\n",
    "    folium.Marker(location=[float(lat), float(lon)], icon=icon, popup=popup).add_to(m)\n",
    "# Finish and save\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('tankers_last_positions_map.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1b745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
